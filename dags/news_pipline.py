from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
import psycopg2
import pandas as pd
import os
import re

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=3),
}

dag = DAG(
    'read_and_insert_data_to_db',
    default_args=default_args,
    description='ƒê·ªçc d·ªØ li·ªáu t·ª´ CSV v√† insert v√†o PostgreSQL',
    schedule_interval='0 09 * * *',
    start_date=datetime(2025, 4, 5),
    catchup=False,
)

def get_db_connection():
    return psycopg2.connect(
        dbname="airflow",
        user="airflow",
        password="airflow",
        host="postgres",
        port="5432"
    )

def create_table_if_not_exists():
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        create_table_query = """
        CREATE TABLE IF NOT EXISTS tintuc (
            id SERIAL PRIMARY KEY,
            title TEXT,
            content TEXT,
            category TEXT,
            source_url TEXT
        );
        """
        cursor.execute(create_table_query)
        conn.commit()
        cursor.close()
        conn.close()
        print("‚úÖ ƒê√£ t·∫°o b·∫£ng 'tintuc' (n·∫øu ch∆∞a t·ªìn t·∫°i).")
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫°o b·∫£ng: {e}")
        raise

def clean_data(df):
    # L√†m s·∫°ch d·ªØ li·ªáu
    for column in ['title', 'summary']:
        df[column] = df[column].astype(str).apply(lambda x: re.sub(r'<.*?>', '', x))  # Lo·∫°i b·ªè th·∫ª HTML
        df[column] = df[column].apply(lambda x: x.lower().strip())  # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    return df

def insert_data_from_csv_to_db():
    file_path = '/input_data/vnexpress_ai_articles.csv'
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {file_path}")

    df = pd.read_csv(file_path)
    df = clean_data(df)

    print("üìÑ D·ªØ li·ªáu sau khi l√†m s·∫°ch:")
    print(df.head())

    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        for _, row in df.iterrows():
            try:
                # Ki·ªÉm tra tr√πng b·∫±ng title v√† url
                cursor.execute(
                    "SELECT id FROM tintuc WHERE title = %s AND source_url = %s",
                    (row['title'], row['url'])
                )
                if cursor.fetchone():
                    print(f"‚ö†Ô∏è B·ªè qua do b·∫£n ghi ƒë√£ t·ªìn t·∫°i: {row['title']} ({row['url']})")
                    continue

                cursor.execute("""
                    INSERT INTO tintuc (title, content, category, source_url)
                    VALUES (%s, %s, %s, %s)
                """, (row['title'], row['summary'], "AI", row['url']))
                conn.commit()
                print(f"‚úÖ ƒê√£ ch√®n: {row['title']}")

            except Exception as e:
                print(f"‚ùå L·ªói khi ch√®n d·ªØ li·ªáu: {e}")
                conn.rollback()

        cursor.close()
        conn.close()

    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi ho·∫∑c ch√®n d·ªØ li·ªáu: {e}")
        raise

# Khai b√°o c√°c task
create_table_task = PythonOperator(
    task_id='create_table_task',
    python_callable=create_table_if_not_exists,
    dag=dag,
)

insert_data_task = PythonOperator(
    task_id='insert_data_from_csv_to_db_task',
    python_callable=insert_data_from_csv_to_db,
    dag=dag,
)

create_table_task >> insert_data_task
